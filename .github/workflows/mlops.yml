name: MLFlow and Snakemake Workflow

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  MLFLOW_URL: https://4af2-160-176-233-39.ngrok-free.app
  PUSHGATEWAY_URL: https://e546-160-179-231-239.ngrok-free.app

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Set up virtual environment and install dependencies
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install mlflow prometheus_client jq
          pip uninstall -y pulp
          pip install pulp==2.5.1
          pip install snakemake
        shell: bash

      - name: Create raw data for processing
        run: |
          # Cr√©er un fichier raw_data.csv avec des donn√©es fictives
          mkdir -p data
          echo "id,name,value" > data/raw_data.csv
          echo "1,Data1,10" >> data/raw_data.csv
          echo "2,Data2,20" >> data/raw_data.csv
        shell: bash

      - name: Create preprocess.py script
        run: |
          mkdir -p scripts
          echo "import pandas as pd
import sys

def preprocess(input_file, output_file):
    # Charger les donn√©es
    df = pd.read_csv(input_file)
    
    # Exemple de pr√©traitement : multiplier les valeurs par 2
    df['value'] = df['value'] * 2
    
    # Sauvegarder le fichier pr√©trait√©
    df.to_csv(output_file, index=False)
    
if __name__ == '__main__':
    preprocess(sys.argv[1], sys.argv[2])" > scripts/preprocess.py
        shell: bash

      - name: Create train.py script
        run: |
          echo "import pandas as pd
import pickle
from sklearn.linear_model import LinearRegression
import sys

def train(input_file, output_file):
    # Charger les donn√©es
    df = pd.read_csv(input_file)
    
    # Exemple d'entra√Ænement : r√©gression lin√©aire
    X = df[['value']]  # Variables explicatives
    y = df['value']    # Variable cible (pour simplifier)
    
    model = LinearRegression()
    model.fit(X, y)
    
    # Sauvegarder le mod√®le
    with open(output_file, 'wb') as f:
        pickle.dump(model, f)

if __name__ == '__main__':
    train(sys.argv[1], sys.argv[2])" > scripts/train.py
        shell: bash

      - name: Create evaluate.py script
        run: |
          echo "import pickle
import pandas as pd
import sys
from sklearn.metrics import mean_squared_error

def evaluate(input_file, model_file, output_file):
    # Charger les donn√©es
    df = pd.read_csv(input_file)
    
    # Charger le mod√®le
    with open(model_file, 'rb') as f:
        model = pickle.load(f)
    
    # Pr√©dictions
    X = df[['value']]
    y_pred = model.predict(X)
    
    # Calcul de l'erreur quadratique moyenne
    mse = mean_squared_error(df['value'], y_pred)
    
    # Sauvegarder les m√©triques
    with open(output_file, 'w') as f:
        f.write(f'Mean Squared Error: {mse}')

if __name__ == '__main__':
    evaluate(sys.argv[1], sys.argv[2], sys.argv[3])" > scripts/evaluate.py
        shell: bash

      - name: Create Snakefile dynamically
        run: |
          # Cr√©er un Snakefile dans le r√©pertoire de travail
          echo "rule all:
            input:
                'results/metrics.txt'

          rule preprocess:
            input:
                'data/raw_data.csv'
            output:
                'data/processed.csv'
            shell:
                'python scripts/preprocess.py {input} {output}'

          rule train_model:
            input:
                'data/processed.csv'
            output:
                'results/model.pkl'
            shell:
                'python scripts/train.py {input} {output}'

          rule evaluate:
            input:
                'results/model.pkl'
            output:
                'results/metrics.txt'
            shell:
                'python scripts/evaluate.py {input} results/model.pkl {output}'" > Snakefile
        shell: bash

      - name: Run Snakemake pipeline
        run: |
          source venv/bin/activate
          snakemake --cores 1
        shell: bash

      - name: Push selected MLFlow metrics to Prometheus
        run: |
          source venv/bin/activate
          declare -A metrics_92f5=( 
            [loss]=0.04144944250583649 
            [mae]=0.1347774024638297 
            [mse]=0.039917658308037784 
            [r2_score]=0.6619863834818595 
            [rmse]=0.19979403972100315 
          )
          declare -A metrics_ad0c=( 
            [aic]=3157.583271036795 
            [bic]=3180.9434357641003 
            [df_model]=5 
            [df_resid]=Inf 
            [llf]=-1573.7916355183975 
            [mse]=0.005455112014267468 
            [scale]=1 
          )
          for key in "${!metrics_92f5[@]}"; do
            value=${metrics_92f5[$key]}
            echo "$key{run=\"92f5893e1dbe4175a3f4313bc89c56b4\"} $value" \
              | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/mlflow_and_snakemake_metrics
          done
          for key in "${!metrics_ad0c[@]}"; do
            value=${metrics_ad0c[$key]}
            echo "$key{run=\"ad0cf78265204f34b84a40aa09895c7f\"} $value" \
              | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/mlflow_and_snakemake_metrics
          done
        shell: bash

      - name: Push global success metric to Prometheus
        run: |
          echo "success 1" \
            | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/mlflow_and_snakemake_metrics
        shell: bash

      - name: Check metrics in PushGateway
        run: |
          echo "üîç V√©rification des m√©triques dans PushGateway..."
          curl -s $PUSHGATEWAY_URL/metrics | grep -E 'scale|loss|mae|mse|aic|bic|llf|r2_score|rmse|df_model|df_resid|success' || echo "‚ö†Ô∏è Pas de m√©triques visibles"
        shell: bash

      - name: Complete Monitoring
        run: echo "‚úÖ Fin de l'ex√©cution, v√©rification via Grafana et Prometheus"
        shell: bash
