name: MLFlow and Snakemake Workflow

on:
  schedule:
    - cron: '0 8 * * *'  # ExÃ©cuter tous les jours Ã  8h00 UTC
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  MLFLOW_URL: https://e06b-41-248-47-247.ngrok-free.app/
  PUSHGATEWAY_URL: https://e546-160-179-231-239.ngrok-free.app/

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Set up virtual environment and install dependencies
        run: |
          python -m venv venv
          source venv/bin/activate
          pip install --upgrade pip
          pip install mlflow prometheus_client jq snakemake pulp==2.4 pulp[cbc] stable-baselines3 gym pandas numpy matplotlib shimmy jupyter nbconvert papermill google-auth google-auth-oauthlib google-api-python-client ipykernel
          pip list | grep google-api-python-client || { echo "Erreur : google-api-python-client non installÃ©"; exit 1; }
        shell: bash

      - name: Install Jupyter kernel
        run: |
          source venv/bin/activate
          python -m ipykernel install --user --name python3 --display-name "Python 3 (venv)"
        shell: bash

      - name: Save Google Drive credentials
        run: |
          echo "${{ secrets.GOOGLE_DRIVE_CLIENT_SECRETS }}" > client_secrets.json
          if [ -s client_secrets.json ]; then
            echo "client_secrets.json crÃ©Ã© avec succÃ¨s."
          else
            echo "Erreur : client_secrets.json est vide ou n'a pas pu Ãªtre crÃ©Ã©."
            exit 1
          fi
        shell: bash

      - name: Save Google Drive token
        run: |
          echo "${{ secrets.GOOGLE_DRIVE_TOKEN }}" > token.json
          if [ -s token.json ]; then
            echo "token.json crÃ©Ã© avec succÃ¨s."
            cat token.json
          else
            echo "Erreur : token.json est vide ou n'a pas pu Ãªtre crÃ©Ã©."
            exit 1
          fi
        shell: bash

      - name: Download notebook and scripts
        run: |
          wget https://raw.githubusercontent.com/elmekadem-narjiss/BackUp_ML/refs/heads/main/Backend/ppo_pipeline.ipynb -O ppo_pipeline.ipynb
          wget https://raw.githubusercontent.com/elmekadem-narjiss/BackUp_ML/refs/heads/main/Backend/train_ppo.py -O train_ppo.py
          wget https://raw.githubusercontent.com/elmekadem-narjiss/BackUp_ML/refs/heads/main/Backend/evaluate_ppo.py -O evaluate_ppo.py
          wget https://raw.githubusercontent.com/elmekadem-narjiss/BackUp_ML/refs/heads/main/Backend/BESSBatteryEnv.py -O BESSBatteryEnv.py
        shell: bash

      - name: Download LSTM predictions from Google Drive
        run: |
          source venv/bin/activate
          echo "VÃ©rification de l'environnement Python..."
          python --version
          pip list | grep google-api-python-client || { echo "Erreur : google-api-python-client non installÃ©"; exit 1; }
          cat > download_file.py << 'EOF'
          import os
          import sys
          from google.oauth2.credentials import Credentials
          from googleapiclient.discovery import build
          from googleapiclient.http import MediaIoBaseDownload
          import io

          print("DÃ©but de l'Ã©tape Download LSTM predictions from Google Drive")

try:
    SCOPES = ['https://www.googleapis.com/auth/drive']
    TOKEN_FILE = 'token.json'

    print("VÃ©rification de l'existence de token.json...")
    if not os.path.exists(TOKEN_FILE):
        print("Erreur : token.json n'existe pas.")
        sys.exit(1)
    print("token.json trouvÃ©.")

    print("Chargement des credentials depuis token.json...")
    creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)
    print("Credentials chargÃ©es avec succÃ¨s.")

    print("Construction du service Google Drive...")
    service = build('drive', 'v3', credentials=creds)
    print("Service Google Drive construit avec succÃ¨s.")

    def download_file(file_name, destination):
        print(f"Recherche du fichier {file_name} dans Google Drive...")
        results = service.files().list(q=f"name='{file_name}' and 'root' in parents", fields="files(id, name)").execute()
        files = results.get('files', [])
        if not files:
            print(f"Fichier {file_name} non trouvÃ© dans Google Drive.")
            return False
        file_id = files[0]['id']
        print(f"Fichier trouvÃ©, ID: {file_id}")

        print(f"TÃ©lÃ©chargement de {file_name} vers {destination}...")
        request = service.files().get_media(fileId=file_id)
        fh = io.FileIO(destination, 'wb')
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
            print(f"TÃ©lÃ©chargement {file_name}: {int(status.progress() * 100)}%")
        print(f"TÃ©lÃ©chargement terminÃ© : {destination}")
        return True

    if download_file('lstm_predictions_charger.csv', 'lstm_predictions_charger.csv'):
        print("Fichier tÃ©lÃ©chargÃ© avec succÃ¨s.")
    else:
        print("Ã‰chec du tÃ©lÃ©chargement du fichier.")
        sys.exit(1)

except Exception as e:
    print(f"Erreur lors du tÃ©lÃ©chargement : {str(e)}")
    sys.exit(1)
EOF
          python download_file.py || { echo "Ã‰chec de l'Ã©tape Download LSTM predictions from Google Drive"; exit 1; }
          rm download_file.py
        shell: bash

      - name: Execute notebook
        run: |
          source venv/bin/activate
          mkdir -p output
          python -m papermill ppo_pipeline.ipynb output/ppo_pipeline_executed.ipynb \
            -p MLFLOW_URL $MLFLOW_URL \
            -p PUSHGATEWAY_URL $PUSHGATEWAY_URL \
            -p output_dir output \
            -p file_path lstm_predictions_charger.csv \
            --kernel python3
        shell: bash

      - name: Push selected MLFlow metrics to Prometheus
        run: |
          source venv/bin/activate
          declare -A metrics_92f5=(
            [loss]=0.04144944250583649
            [mae]=0.1347774024638297
            [mse]=0.039917658308037784
            [r2_score]=0.6619863834818595
            [rmse]=0.19979403972100315
          )
          declare -A metrics_ad0c=(
            [aic]=3157.583271036795
            [bic]=3180.9434357641003
            [df_model]=5
            [df_resid]=Inf
            [llf]=-1573.7916355183975
            [mse]=0.005455112014267468
            [scale]=1
          )
          for key in "${!metrics_92f5[@]}"; do
            value=${metrics_92f5[$key]}
            echo "$key{run=\"92f5893e1dbe4175a3f4313bc89c56b4\"} $value" \
              | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/mlflow_and_snakemake_metrics
          done
          for key in "${!metrics_ad0c[@]}"; do
            value=${metrics_ad0c[$key]}
            echo "$key{run=\"ad0cf78265204f34b84a40aa09895c7f\"} $value" \
              | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/mlflow_and_snakemake_metrics
          done

          # Pousser les mÃ©triques PPO
          if [ -f output/ppo_bess_model_metrics.json ]; then
            TRAIN_METRICS=$(cat output/ppo_bess_model_metrics.json | jq -r 'to_entries | .[] | "\\(.key){run=\\\"ppo_training\\\"} \\(.value)"')
            while IFS= read -r metric; do
              echo "$metric" | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/ppo_metrics
            done <<< "$TRAIN_METRICS"
          fi

          if [ -f output/evaluation_metrics.json ]; then
            EVAL_METRICS=$(cat output/evaluation_metrics.json | jq -r 'to_entries | .[] | "\\(.key){run=\\\"ppo_evaluation\\\"} \\(.value)"')
            while IFS= read -r metric; do
              echo "$metric" | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/ppo_metrics
            done <<< "$EVAL_METRICS"
          fi
        shell: bash

      - name: Push global success metric to Prometheus
        run: |
          echo "success 1" \
            | curl --data-binary @- $PUSHGATEWAY_URL/metrics/job/mlflow_and_snakemake_metrics
        shell: bash

      - name: Check metrics in PushGateway
        run: |
          echo "ðŸ” VÃ©rification des mÃ©triques dans PushGateway..."
          curl -s $PUSHGATEWAY_URL/metrics | grep -E 'scale|loss|mae|mse|aic|bic|llf|r2_score|rmse|df_model|df_resid|success|avg_reward|avg_cycles|avg_accuracy|total_reward|cycles|accuracy' || echo "âš ï¸ Pas de mÃ©triques visibles"
        shell: bash

      - name: Complete Monitoring
        run: echo "âœ… Fin de l'exÃ©cution, vÃ©rification via Grafana et Prometheus"
        shell: bash
